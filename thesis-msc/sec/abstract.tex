% %
% MOTIVATION
% %
The containers orchestration in Cloud environment is a disruptive technology that opens cutting-edge research fields and industrial applications.
%
First, Cloud computing provides applications with the possibility to scale over a theoretically infinite pool of resources in a pay-per-use fashion.
%
Next, the deployment of applications as containerized micro-services allows a fine-grained control over components to be scaled.
%
%
% %
% PROBLEM STATEMENT
% %
Due to the high variability of workloads, manual and static scaling are not an effective approaches.
%
Since scaling decisions have both monetary and performance costs, the adaptive auto-scaling of containers is a strategic asset for Cloud-centric industries.


% %
% APPROACH
% %
In this work, we consider the elastic auto-scaling problem in the field of containers orchestration and focus on the adoption of Reinforcement Learning for the proactive run-time adaption of the scaling policy in the OpenShift environment.
%
Our main contribution is the adoption of Artificial Intelligence to overcome the limitations of the widely adopted static threshold-based approaches.

%
%
% %
% RESULTS
% %
The experimental results show that our solution converges to an auto-scaling policy that meets QoS requirements while reducing the cost of the infrastructure. 
%
%
% %
% CONCLUSIONS
% %
Although there is still a long way to go to speed-up the learning convergence, our work show that the application of Reinforcement Learning for elastic containers auto-scaling should be a promising research field for Cloud-driven industries.
